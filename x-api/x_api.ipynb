{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj80UESf3t6J",
        "outputId": "cb1b95c9-a748-4753-aed7-b9dd27a0cbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. New timeline posts saved: 636. New discussion posts saved: 98.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "X_API_BASE = \"https://api.x.com/2\"\n",
        "\n",
        "\n",
        "def _sleep_backoff(attempt: int) -> None:\n",
        "    # Exponential backoff with a small cap\n",
        "    time.sleep(min(60, 2 ** attempt))\n",
        "\n",
        "\n",
        "def _max_post_id(posts: List[dict]) -> Optional[str]:\n",
        "    # Post IDs are large; keep them as strings but compare as ints\n",
        "    if not posts:\n",
        "        return None\n",
        "    return str(max(int(p[\"id\"]) for p in posts if \"id\" in p))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class XTrackerConfig:\n",
        "    bearer_token: str\n",
        "    usernames: List[str]                 # 13 accounts (council + 12 members)\n",
        "    discussion_query: str                # recent search query\n",
        "    db_path: str = \"x_tracker.sqlite\"\n",
        "    state_path: str = \"x_tracker_state.json\"\n",
        "    user_post_fields: str = \"created_at,author_id,conversation_id,public_metrics\"\n",
        "    tweet_fields: str = \"created_at,author_id,conversation_id,public_metrics\"\n",
        "    max_results_timeline: int = 50       # 5..100 per docs\n",
        "    max_results_search: int = 100        # 10..100 for recent search typically\n",
        "\n",
        "\n",
        "class XTracker:\n",
        "    def __init__(self, cfg: XTrackerConfig):\n",
        "        self.cfg = cfg\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\"Authorization\": f\"Bearer {cfg.bearer_token}\"})\n",
        "\n",
        "        self._init_db()\n",
        "\n",
        "    def _init_db(self) -> None:\n",
        "        con = sqlite3.connect(self.cfg.db_path)\n",
        "        cur = con.cursor()\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS posts (\n",
        "                id TEXT PRIMARY KEY,\n",
        "                source TEXT NOT NULL,            -- \"timeline\" or \"search\"\n",
        "                author_id TEXT,\n",
        "                author_username TEXT,\n",
        "                created_at TEXT,\n",
        "                text TEXT,\n",
        "                raw_json TEXT\n",
        "            )\n",
        "            \"\"\"\n",
        "        )\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS users (\n",
        "                username TEXT PRIMARY KEY,\n",
        "                user_id TEXT NOT NULL\n",
        "            )\n",
        "            \"\"\"\n",
        "        )\n",
        "        con.commit()\n",
        "        con.close()\n",
        "\n",
        "    def _load_state(self) -> dict:\n",
        "        if not os.path.exists(self.cfg.state_path):\n",
        "            return {\"since_id_by_user_id\": {}, \"search_since_id\": None}\n",
        "        with open(self.cfg.state_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def _save_state(self, state: dict) -> None:\n",
        "        with open(self.cfg.state_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(state, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    def _request_json(self, method: str, url: str, params: Optional[dict] = None) -> dict:\n",
        "        for attempt in range(0, 6):\n",
        "            resp = self.session.request(method, url, params=params, timeout=30)\n",
        "            if resp.status_code == 429:\n",
        "                _sleep_backoff(attempt)\n",
        "                continue\n",
        "            resp.raise_for_status()\n",
        "            return resp.json()\n",
        "        raise RuntimeError(\"Too many 429 rate limit responses. Try reducing frequency/max_results.\")\n",
        "\n",
        "    def get_user_ids_bulk(self) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        Bulk lookup: GET /2/users/by?usernames=...\n",
        "        Docs: \"Get Users by usernames\" quickstart exists; limit up to 100 usernames.\n",
        "        \"\"\"\n",
        "        usernames = [u.lstrip(\"@\") for u in self.cfg.usernames]\n",
        "        url = f\"{X_API_BASE}/users/by\"\n",
        "        params = {\"usernames\": \",\".join(usernames), \"user.fields\": \"username\"}\n",
        "\n",
        "        data = self._request_json(\"GET\", url, params=params)\n",
        "        users = data.get(\"data\", [])\n",
        "\n",
        "        mapping: Dict[str, str] = {}\n",
        "        for u in users:\n",
        "            mapping[u[\"username\"].lower()] = u[\"id\"]\n",
        "\n",
        "        # Persist mapping\n",
        "        con = sqlite3.connect(self.cfg.db_path)\n",
        "        cur = con.cursor()\n",
        "        for username in usernames:\n",
        "            user_id = mapping.get(username.lower())\n",
        "            if user_id:\n",
        "                cur.execute(\n",
        "                    \"INSERT OR REPLACE INTO users (username, user_id) VALUES (?, ?)\",\n",
        "                    (username.lower(), user_id),\n",
        "                )\n",
        "        con.commit()\n",
        "        con.close()\n",
        "\n",
        "        missing = [u for u in usernames if u.lower() not in mapping]\n",
        "        if missing:\n",
        "            print(f\"Warning: Could not resolve user IDs for: {missing}\")\n",
        "\n",
        "        return mapping\n",
        "\n",
        "    def _get_username_for_id(self, user_id: str) -> Optional[str]:\n",
        "        con = sqlite3.connect(self.cfg.db_path)\n",
        "        cur = con.cursor()\n",
        "        cur.execute(\"SELECT username FROM users WHERE user_id = ?\", (user_id,))\n",
        "        row = cur.fetchone()\n",
        "        con.close()\n",
        "        return row[0] if row else None\n",
        "\n",
        "    def fetch_timeline_posts(self, user_id: str, since_id: Optional[str]) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Timeline: GET /2/users/{id}/posts\n",
        "        \"\"\"\n",
        "        url = f\"{X_API_BASE}/users/{user_id}/posts\"\n",
        "        params = {\n",
        "            \"max_results\": self.cfg.max_results_timeline,\n",
        "            \"tweet.fields\": self.cfg.user_post_fields,  # docs use tweet.fields for Post object fields\n",
        "        }\n",
        "        if since_id:\n",
        "            params[\"since_id\"] = since_id\n",
        "\n",
        "        data = self._request_json(\"GET\", url, params=params)\n",
        "        return data.get(\"data\", [])\n",
        "\n",
        "    def fetch_recent_discussion(self, since_id: Optional[str]) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Recent Search: GET /2/tweets/search/recent\n",
        "        \"\"\"\n",
        "        url = f\"{X_API_BASE}/tweets/search/recent\"\n",
        "        params = {\n",
        "            \"query\": self.cfg.discussion_query,\n",
        "            \"max_results\": self.cfg.max_results_search,\n",
        "            \"tweet.fields\": self.cfg.tweet_fields,\n",
        "        }\n",
        "        if since_id:\n",
        "            params[\"since_id\"] = since_id\n",
        "\n",
        "        data = self._request_json(\"GET\", url, params=params)\n",
        "        return data.get(\"data\", [])\n",
        "\n",
        "    def _upsert_posts(self, posts: List[dict], source: str, author_username: Optional[str] = None) -> int:\n",
        "        if not posts:\n",
        "            return 0\n",
        "\n",
        "        con = sqlite3.connect(self.cfg.db_path)\n",
        "        cur = con.cursor()\n",
        "        inserted = 0\n",
        "\n",
        "        for p in posts:\n",
        "            post_id = p.get(\"id\")\n",
        "            if not post_id:\n",
        "                continue\n",
        "            raw_json = json.dumps(p, ensure_ascii=False)\n",
        "\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                INSERT OR IGNORE INTO posts\n",
        "                (id, source, author_id, author_username, created_at, text, raw_json)\n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "                \"\"\",\n",
        "                (\n",
        "                    post_id,\n",
        "                    source,\n",
        "                    p.get(\"author_id\"),\n",
        "                    author_username,\n",
        "                    p.get(\"created_at\"),\n",
        "                    p.get(\"text\"),\n",
        "                    raw_json,\n",
        "                ),\n",
        "            )\n",
        "            if cur.rowcount == 1:\n",
        "                inserted += 1\n",
        "\n",
        "        con.commit()\n",
        "        con.close()\n",
        "        return inserted\n",
        "\n",
        "    def run_once(self) -> None:\n",
        "        \"\"\"\n",
        "        Run one collection pass. Schedule this with cron/GitHub Actions/etc.\n",
        "        \"\"\"\n",
        "        state = self._load_state()\n",
        "\n",
        "        # Ensure we have user IDs cached\n",
        "        user_map = self.get_user_ids_bulk()\n",
        "        user_ids = [uid for uid in user_map.values() if uid]\n",
        "\n",
        "        # 1) Timelines for the 14 accounts\n",
        "        total_new_timeline = 0\n",
        "        for user_id in user_ids:\n",
        "            since_id = state[\"since_id_by_user_id\"].get(user_id)\n",
        "            posts = self.fetch_timeline_posts(user_id=user_id, since_id=since_id)\n",
        "\n",
        "            username = self._get_username_for_id(user_id)\n",
        "            inserted = self._upsert_posts(posts, source=\"timeline\", author_username=username)\n",
        "            total_new_timeline += inserted\n",
        "\n",
        "            new_since = _max_post_id(posts)\n",
        "            if new_since:\n",
        "                state[\"since_id_by_user_id\"][user_id] = new_since\n",
        "\n",
        "        # 2) General discussion via Recent Search\n",
        "        search_since = state.get(\"search_since_id\")\n",
        "        discussion_posts = self.fetch_recent_discussion(since_id=search_since)\n",
        "        total_new_search = self._upsert_posts(discussion_posts, source=\"search\", author_username=None)\n",
        "\n",
        "        new_search_since = _max_post_id(discussion_posts)\n",
        "        if new_search_since:\n",
        "            state[\"search_since_id\"] = new_search_since\n",
        "\n",
        "        self._save_state(state)\n",
        "\n",
        "        print(\n",
        "            f\"Done. New timeline posts saved: {total_new_timeline}. \"\n",
        "            f\"New discussion posts saved: {total_new_search}.\"\n",
        "        )\n",
        "\n",
        "\n",
        "def build_discussion_query(usernames: List[str]) -> str:\n",
        "    \"\"\"\n",
        "    Build a conservative query for DC Council discussion:\n",
        "    - keyword phrases\n",
        "    - @mentions of council + members\n",
        "    - excludes retweets to reduce volume (optional)\n",
        "    \"\"\"\n",
        "    handles = [u.lstrip(\"@\") for u in usernames]\n",
        "    mention_terms = \" OR \".join([f\"@{h}\" for h in handles])\n",
        "\n",
        "    # You can tune keywords to reduce volume and cost.\n",
        "    keyword_terms = '(\"DC Council\" OR \"Council of the District of Columbia\" OR \"DC City Council\" OR \"Council of DC\")'\n",
        "\n",
        "    # You can add lang:en or -is:reply if needed, but be careful not to miss relevant posts.\n",
        "    return f\"({keyword_terms} OR ({mention_terms})) -is:retweet lang:en\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #bearer_token = os.environ.get(\"X_BEARER_TOKEN\", \"\").strip()\n",
        "    bearer_token = \"AAAAAAAAAAAAAAAAAAAAAKvy7AEAAAAApLfuKEe9QGv6OlhnrBw3ngk1fM8%3DfKylKRecx4aQXn42qmpP6SFqjKY5pw6IRp9CGotpZVwHmGPInb\"\n",
        "    if not bearer_token:\n",
        "        raise RuntimeError('Set env var \"X_BEARER_TOKEN\" to your X API Bearer Token.')\n",
        "\n",
        "    usernames = [\n",
        "        \"CouncilofDC\",\n",
        "        \"ChmnMendelson\",\n",
        "        \"CMAnitaBondsDC\",\n",
        "        \"RobertWhite_DC\",\n",
        "        \"chenderson\",\n",
        "        \"DoniCrawford\",\n",
        "        \"BrianneKNadeau\",\n",
        "        \"CMBrookePinto\",\n",
        "        \"CMFrumin\",\n",
        "        \"Janeese4DC\",\n",
        "        \"ZacharyforWard5\",\n",
        "        \"charlesallen\",\n",
        "        \"WendellforWard7\"\n",
        "        #,\"trayonwhite\" # ward 8\n",
        "    ]\n",
        "\n",
        "    discussion_query = build_discussion_query(usernames)\n",
        "\n",
        "    cfg = XTrackerConfig(\n",
        "        bearer_token=bearer_token,\n",
        "        usernames=usernames,\n",
        "        discussion_query=discussion_query,\n",
        "        db_path=\"x_tracker.sqlite\",\n",
        "        state_path=\"x_tracker_state.json\",\n",
        "    )\n",
        "\n",
        "    tracker = XTracker(cfg)\n",
        "    tracker.run_once()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"x_tracker.sqlite\")\n",
        "files.download(\"x_tracker_state.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zpTQkHb-Bxt6",
        "outputId": "611867f8-9314-476e-bf36-47c996e41868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97042348-0137-4745-825c-b359cb7fdf5b\", \"x_tracker.sqlite\", 692224)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_651d27ec-526a-4ca0-a590-bb83a5c85409\", \"x_tracker_state.json\", 655)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}